# IT-RAG Assistant âš¡ğŸ¤–

**IT-RAG Assistant** est un **assistant intelligent interne** capable de rÃ©pondre aux questions des techniciens IT Ã  partir dâ€™un **PDF de support IT** (procÃ©dures, incidents, FAQ). Il utilise les derniÃ¨res technologies dâ€™IA pour fournir des rÃ©ponses fiables et contextuelles, tout en Ã©tant industrialisÃ©, versionnÃ© et monitorÃ©.

---

## ğŸš€ Objectif du projet

IT-RAG Assistant vise Ã  :  
- RÃ©pondre rapidement aux **questions rÃ©currentes** des techniciens IT  
- **Guider les interventions** lors dâ€™incidents ou procÃ©dures complexes  
- **Centraliser et standardiser** les procÃ©dures IT Ã  partir dâ€™un PDF mis Ã  jour  
- Fournir un service **fiable, Ã©volutif et monitorÃ©** grÃ¢ce Ã  un pipeline RAG industrialisÃ©

---

## ğŸ’¡ FonctionnalitÃ©s

- **Ingestion et prÃ©paration du PDF** : extraction et dÃ©coupage en chunks avec mÃ©tadonnÃ©es  
- **Recherche sÃ©mantique** : gÃ©nÃ©ration dâ€™embeddings via HuggingFace + stockage dans ChromaDB  
- **Pipeline RAG** : LangChain pour gÃ©nÃ©rer des rÃ©ponses prÃ©cises Ã  partir du PDF  
- **Backend FastAPI + PostgreSQL** : API sÃ©curisÃ©e, gestion des utilisateurs et historique des questions  
- **Clustering non supervisÃ©** : regroupe les questions frÃ©quentes pour analyse  
- **Suivi et versionnement MLflow** : tracabilitÃ© et reproductibilitÃ© des modÃ¨les  
- **CI/CD & dÃ©ploiement cloud-native** : Docker + Kubernetes pour un service scalable et monitorÃ©  

---

## ğŸ› ï¸ Technologies utilisÃ©es

| Composant | Technologie |
|------------|------------|
| LLM / RAG | LangChain, Gemini / HuggingFace |
| Extraction PDF | PyPDFLoader |
| Vector DB | ChromaDB |
| Backend | FastAPI, PostgreSQL |
| Clustering | KMeans (ML non supervisÃ©) |
| Monitoring & versioning | MLflow |
| CI/CD & DÃ©ploiement | GitHub Actions, Docker, Kubernetes |

---

## âš™ï¸ Architecture

```mermaid
graph LR
A[PDF Support IT] --> B[DÃ©coupage en chunks]
B --> C[Embeddings HuggingFace]
C --> D[ChromaDB Vector Store]
D --> E[Retriever LangChain]
E --> F[LLM RAG]
F --> G[FastAPI Backend]
G --> H[Utilisateur IT]
```

## ğŸ“¦ Installation

1. Cloner le projet :

```
git clone https://github.com/Assma-IBIKAS/IT-RAG-Assistant.git
cd IT-RAG-Assistant
```
2. CrÃ©er un environnement Python :
```
python -m venv venv
source venv/bin/activate  # Linux/Mac
venv\Scripts\activate     # Windows
```
3. Installer les dÃ©pendances :
```
pip install -r requirements.txt
```
4. Configurer les variables dâ€™environnement pour le LLM et PostgreSQL.

## ğŸ“Š DÃ©ploiement

* Docker + Kubernetes pour un dÃ©ploiement scalable

* FastAPI pour exposer le backend

* MLflow pour le suivi et la version des modÃ¨les

* GitHub Actions pour automatiser CI/CD
## ğŸ¤ Contribution

Contributions bienvenues !

* Fork le projet

* CrÃ©er une branche feature/ta-fonctionnalitÃ©

* Commit tes changements

* Pull request
